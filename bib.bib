@article{VoVan2010,
author = {{Vo Van}, Tai and Pham-Gia, T.},
doi = {10.1080/02664760903186049},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/02664760903186049.pdf:pdf},
isbn = {0266476090},
issn = {0266-4763},
journal = {Journal of Applied Statistics},
mendeley-groups = {Dissertation},
number = {11},
pages = {1891--1910},
title = {{Clustering probability distributions}},
volume = {37},
year = {2010}
}
@article{Goh2008,
abstract = {We present an algorithm for grouping families of probability density functions (pdfs). We exploit the fact that under the$\backslash$nsquare-root re-parametrization, the space of pdfs forms a Riemannian manifold, namely the unit Hilbert sphere. An immediate$\backslash$nconsequence of this re-parametrization is that different families of pdfs form different submanifolds of the unit Hilbert$\backslash$nsphere. Therefore, the problem of clustering pdfs reduces to the problem of clustering multiple submanifolds on the unit Hilbert$\backslash$nsphere. We solve this problem by first learning a low-dimensional representation of the pdfs using generalizations of local$\backslash$nnonlinear dimensionality reduction algorithms from Euclidean to Riemannian spaces. Then, by assuming that the pdfs from different$\backslash$ngroups are separated, we show that the null space of a matrix built from the local representation gives the segmentation of$\backslash$nthe pdfs. We also apply of our approach to the texture segmentation problem in computer vision.},
author = {Goh, Alvina and Vidal, Ren\'{e}},
doi = {10.1007/978-3-540-87479-9\_43},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/ECML2008\_PDF.pdf:pdf},
isbn = {354087478X},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Manifold clustering,Manifold learning,Probability density functions},
mendeley-groups = {Dissertation},
number = {PART 1},
pages = {377--392},
title = {{Unsupervised riemannian clustering of probability density functions}},
volume = {5211 LNAI},
year = {2008}
}
@article{Jiang2013,
author = {Jiang, Bin and Pei, Jian and Member, Senior},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06051435.pdf:pdf},
journal = {IEEE Transactions on Knowledge and Data Engineering},
mendeley-groups = {Dissertation},
number = {4},
pages = {751--763},
title = {{on Probability Distribution Similarity}},
volume = {25},
year = {2013}
}
@article{Fortunato2010,
abstract = {The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks. ?? 2009 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {0906.0612},
author = {Fortunato, Santo},
doi = {10.1016/j.physrep.2009.11.002},
eprint = {0906.0612},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/0906.0612v2.pdf:pdf},
isbn = {0370-1573},
issn = {03701573},
journal = {Physics Reports},
keywords = {Clusters,Graphs,Statistical physics},
mendeley-groups = {Dissertation},
number = {3-5},
pages = {75--174},
pmid = {22166104},
title = {{Community detection in graphs}},
volume = {486},
year = {2010}
}
@book{hastie2008,
address = {Stanford},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
edition = {2},
mendeley-groups = {Dissertation},
publisher = {Springer},
title = {{The Elements of Statistical Learning}},
year = {2008}
}
@book{markel1976,
address = {Santa Barbara},
author = {Markel, J.D. and Gray, A.H. Jr.},
mendeley-groups = {Dissertation},
publisher = {Springer-Verlag},
title = {{Linear Prediction of Speech}},
year = {1976}
}
@book{Murphy2012,
address = {Cambridge},
author = {Murphy, Kevin P.},
mendeley-groups = {Dissertation},
publisher = {MIT Press},
title = {{Machine Learning: A Probabilistic Perspective}},
year = {2012}
}
@article{Girvan2002,
abstract = {10.1073/pnas.122653799 A number of recent studies have focused on the statistical properties of networked systems such as social networks and the Worldwide Web. Researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. We propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well known\^{a}a collaboration network and a food web\^{a}and find that it detects significant and informative community divisions in both cases.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0112110},
author = {Girvan, M. and Newman, M. E. J.},
doi = {10.1073/pnas.122653799},
eprint = {0112110},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/pq1202007821.pdf:pdf},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
mendeley-groups = {Dissertation},
number = {12},
pages = {7821--7826},
pmid = {12060727},
primaryClass = {cond-mat},
title = {{Community structure in social and biological networks}},
url = {http://www.pnas.org/content/99/12/7821.abstract$\backslash$nhttp://www.pnas.org/content/99/12/7821.full.pdf$\backslash$nhttp://www.pnas.org/cgi/content/abstract/99/12/7821},
volume = {99},
year = {2002}
}
@article{Mporas2011,
abstract = {In this paper, we face the problem of phonetic segmentation under the hierarchical clustering framework. We extend the framework with an unsupervised segmentation algorithm based on a divisive clustering technique and compare both approaches: agglomerative nesting (Bottom-up) against divisive analysis (Top-down). As both approaches require prior knowledge of the number of segments to be estimated, we present a stopping criterion in order to make these algorithms become standalone. This criterion provides an estimation of the underlying number of segments inside the speech acoustic data. The evaluation of both approaches using the stopping criterion reveals good compromise between boundary estimation (Hit rate) and number of segments estimation (over-under segmentation).},
author = {Mporas, Iosif and Ganchev, Todor and Kocsis, Otilia and Fakotakis, Nikos and Jahn, Olaf and Riede, Klaus and Schuchmann, Karl L. and Gracia, Ciro and Binefa, Xavier},
doi = {10.1109/ICTAI.2012.110},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06495122.pdf:pdf;:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/07074040.pdf:pdf},
isbn = {9780769549156},
issn = {22195491},
journal = {European Signal Processing Conference},
keywords = {Hierarchical clustering,Speech segmentation,Stopping criterion,acoustic bird species recognition,automatic recognition,bioacoustics,biodiversity informatics},
mendeley-groups = {Dissertation},
number = {Eusipco},
pages = {778--781},
title = {{On hierarchical clustering for speech phonetic segmentation}},
volume = {1},
year = {2011}
}
@article{Bello,
author = {Bello, Juan Pablo},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/signals/LPC.pdf:pdf},
mendeley-groups = {Dissertation,Dissertation/Formants},
title = {{The human speech system Source-filter model Parameters Filter Amplifier}},
year = {2010}
}
@article{Banerjee2008,
abstract = {The performance of the acoustic models is highly reflective on the overall performance of any continuous speech recognition system. Hence generation of an accurate and robust acoustic model holds the key to satisfactory recognition performance. As phones are found to vary according to the position of occurrence within a particular word, context information is of prime importance in acoustic modeling of phonetic signals. In this paper we look at the effect of triphone-based acoustic modeling over monophone based acoustic models in the context of continuous speech recognition in Bengali. Keeping in mind the lack of training resources for triphone-based acoustic modeling in Bengali, we have also described herein, the method of generating triphone clusters using decision tree based techniques. These triphone clusters have then been used to generate tied-state triphone based acoustic models to be used in a continuous speech recognizer.},
author = {Banerjee, P. and Garg, G. and Mitra, P. and Basu, a.},
doi = {10.1109/ICPR.2008.4761657},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/04761657.pdf:pdf},
isbn = {978-1-4244-2174-9},
issn = {1051-4651},
journal = {2008 19th International Conference on Pattern Recognition},
mendeley-groups = {Dissertation},
pages = {8--11},
title = {{Application of triphone clustering in acoustic modeling for continuous speech recognition in Bengali}},
year = {2008}
}
@article{Jancovic2013,
author = {Jancovic, Peter and Kokuer, Munevver and Zakeri, Masoud and Russell, Martin},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06811728.pdf:pdf},
isbn = {9780992862602},
issn = {22195491},
journal = {European Signal Processing Conference},
keywords = {bird,clustering,dynamic time warping,segmentation,sinusoid,tonal,unsupervised,vocalisation},
mendeley-groups = {Dissertation},
pages = {1--5},
title = {{Unsupervised discovery of acoustic patterns in bird vocalisations employing DTW and clustering}},
year = {2013}
}
@article{Joly2014,
author = {Joly, Alexis and Bonnet, Pierre and Rauber, Andreas and Fisher, Robert B},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/p31-joly.pdf:pdf},
isbn = {9781450324014},
mendeley-groups = {Dissertation},
pages = {31--36},
title = {{Are Species Identification Tools Biodiversity-friendly ? A cross-tasks analysis of LifeCLEF 2014 results}},
year = {2014}
}
@article{Li2013,
author = {Li, Na and Jiang, Weiwu and Meng, Helen and Li, Zhifeng},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06639167.pdf:pdf},
isbn = {9781479903566},
journal = {Processing},
mendeley-groups = {Dissertation},
pages = {7726--7730},
title = {{CLUSTERING SIMILAR ACOUSTIC CLASSES IN THE FISHERVOICE FRAMEWORK College of Marine Engineering , Northwestern Polytechnical University , Xi ’ an , China , Shenzhen key lab of CVPR , Shenzhen Institutes of Advanced Technology , CAS , China , The Chinese Un}},
year = {2013}
}
@article{Lu2012,
author = {Lu, Zhubing and Wang, Jian and Li, Yuzhou},
doi = {10.1109/ICCSE.2012.6295120},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06295120.pdf:pdf},
isbn = {9781467302425},
journal = {ICCSE 2012 - Proceedings of 2012 7th International Conference on Computer Science and Education},
keywords = {Community detection,Community evaluation,Complex network,Overlapping community},
mendeley-groups = {Dissertation},
number = {Iccse},
pages = {486--490},
title = {{An overview on overlapping community detection}},
year = {2012}
}
@article{Shirai1989,
author = {Shirai, Katsuhiko and Aoki, Noriyuki and Hosaka, Naoki},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/00266499.pdf:pdf},
journal = {Distribution},
mendeley-groups = {Dissertation},
pages = {604--607},
title = {{Multi-Level Clustering of Acoustic Features}},
volume = {1},
year = {1989}
}
@article{Benson2004,
abstract = { Summary form only given. This paper applies nature inspired concepts and techniques from computer science, i.e. evolutionary computing, to gain a better understanding of the evolutionary history of birdsong. Notes are created and evolved according to fitness criteria to produce accurate and recognizable birdsong notes. The successful parallel simulation that was produced for this study can provide an excellent framework for future experimentation to determine how and why birdsongs evolved.},
author = {Benson, R.H. and Moore, M.D.},
doi = {10.1109/IPDPS.2004.1303162},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/01303162.pdf:pdf},
isbn = {0-7695-2132-0},
journal = {18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.},
mendeley-groups = {Dissertation},
number = {C},
pages = {2--5},
title = {{Simulation of birdsong evolution using a parallel genetic algorithm}},
volume = {00},
year = {2004}
}
@article{Chou2008,
abstract = {In this study, a bird species recognition system based on their sounds is proposed. In this system, the birdsong of a bird species is segmented into many syllables, from which several primary frequency sequences can be obtained. By using the statistics of the principle frequency sequences, all the syllables are clustered with the fuzzy C-mean clustering method so that each syllable group can be modeled by a hidden Markov model (HMM) characterizing the features of the song of the bird species. Using the Viterbi algorithm, the recognition process is achieved by finding the template bird species that has the most probable HMMs matching the frequency sequences of the test birdsong. Experimental results show that the proposed system can achieve a recognition rate of over 78\% for 420 kinds of bird species.},
author = {Chou, Chih Hsun and Lee, Chang Hsing and Ni, Hui Wen},
doi = {10.1109/ICICIC.2007.199},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/04427788.pdf:pdf},
isbn = {0769528821},
journal = {Second International Conference on Innovative Computing, Information and Control, ICICIC 2007},
keywords = {Bird Species Recognition by Comparing the HMMs of},
mendeley-groups = {Dissertation},
number = {707},
pages = {2--5},
title = {{Bird species recognition by comparing the HMMs of the syllables}},
year = {2008}
}
@article{Chou2009,
abstract = {In this study, a method for birdsong recognition is proposed. In this method, after detecting the range of each syllable, birdsong sections containing a period of syllables were segmented. For each syllable of a birdsong section, the first five orders MFCCs were computed, and the same order MFCCs of all syllables were aligned so that wavelet transformation can be applied to compute the feature vector of the birdsong section. By using neural network as the classifier, the proposed method was applied to recognize the birdsongs of 420 bird species.},
author = {Chou, Chih Hsun and Liu, Pang Hsin},
doi = {10.1109/UIC-ATC.2009.85},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/05319240.pdf:pdf},
isbn = {9780769537375},
journal = {UIC-ATC 2009 - Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in Conjunction with the UIC'09 and ATC'09 Conferences},
mendeley-groups = {Dissertation},
number = {707},
pages = {189--193},
title = {{Bird species recognition by wavelet transformation of a section of birdsong}},
year = {2009}
}
@article{Chou2008a,
abstract = {Birdsongs are typically divided into four hierarchical levels: note, syllable, phrase, and song, of which syllable plays an important role in bird species recognition. To improve the recognition rate of birdsongs, in this study an enhanced syllable segmentation method based on R-S endpoint detection method was presented. Furthermore, a decision based neural network with suitable reinforcement learning rule was developed as the classifier. The proposed methods combined with the well-known MFCCs feature vector form a birdsong recognition system that was applied to two recognition problems: one is the recognition of a set of arbitrary syllables and the other is the recognition of a section of a birdsong. Experimental results show the performances of the proposed methods.},
author = {Chou, Chih Hsun and Liu, Pang Hsin and Cai, Bingjing},
doi = {10.1109/APSCC.2008.6},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/04780764.pdf:pdf},
isbn = {9780769534732},
journal = {Proceedings of the 3rd IEEE Asia-Pacific Services Computing Conference, APSCC 2008},
mendeley-groups = {Dissertation},
pages = {745--750},
title = {{On the studies of syllable segmentation and improving MFCCs for automatic birdsong recognition}},
year = {2008}
}
@article{Evangelista2014,
author = {Evangelista, Thiago L.F. and Priolli, Thales M. and Jr, Carlos N. Silla and Angelico, Bruno a. and a.a. Kaestner, Celso},
doi = {10.1109/ISM.2014.46},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/07033024.pdf:pdf},
isbn = {978-1-4799-4311-1},
journal = {2014 IEEE International Symposium on Multimedia},
keywords = {-signal processing,bird species identification,learning,machine,pattern recognition},
mendeley-groups = {Dissertation},
pages = {223--228},
title = {{Automatic Segmentation of Audio Signals for Bird Species Identification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7033024},
year = {2014}
}
@article{Franzen2003,
abstract = { To better understand the environment we are living, especially animals and birds around us, we need to study their behavior and the way of their communication. This paper addresses the problem of classifying bird species of interests using the digital signals of recorded bird songs. First, through comparisons of speech and bird song signals and the experiments, we propose a simple model (similar to that of the speech) for generating synthetic bird songs. We then propose a key-bird-song searching method for the recognition of bird species of interest. This is possible since bird songs appear to be simpler as compared to human speech. A hierarchical classification method is then suggested. In the coarse level of the classification, only candidate songs from those birds whose time-dependent coupled sound patterns are 'close' to that of the species of interest are chosen as the candidates. In the fine level, time-frequency 'format' trajectory-related features from the candidate songs are used for the classification. A case study is conducted for the recognition of a selected bird species, the Great Tit. Preliminary experimental results from using five different bird species and 87 songs have shown promising results in recognizing the selected bird species of interest, with less than 3\% of classification errors.},
author = {Franzen, a. and Gu, I.Y.H.},
doi = {10.1109/ICSMC.2003.1243926},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/01243926.pdf:pdf},
isbn = {0-7803-7952-7},
issn = {1062-922X},
journal = {SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483)},
mendeley-groups = {Dissertation},
title = {{Classification of bird species by using key song searching: a comparative study}},
volume = {1},
year = {2003}
}
@article{International2011,
abstract = {The goal of this work was to explore modeling techniques to improve bird species classification from audio samples. We first developed an unsupervised approach to obtain approximate note models from acoustic features. From these note models we created a bird species recognition system by leveraging a phone n-gram statistical model developed for speaker recognition applications. We found competitive performance from the note n-gram system compared to a Gaussian mixture model baseline using the same acoustic features. We found an important gain by doing score-level combination relative to the best individual system results. We verified that on most of the bird species under study there was a gain from system combination},
author = {International, S R I and Park, Menlo and Data, Bird Song and Guide, Field and Songs, Bird and Ed, Second and America, North and Guide, a Field and Ed, Third},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/05946410.pdf:pdf},
isbn = {9781457705397},
mendeley-groups = {Dissertation},
pages = {341--344},
title = {{BIRD SPECIES RECOGNITION COMBINING ACOUSTIC AND SEQUENCE MODELING Martin Graciarena , Michelle Delplanche , Elizabeth Shriberg , Andreas Stolcke}},
year = {2011}
}
@article{Jian2014,
author = {Jian, Li and Lei, Zhang and Baoping, Yan},
doi = {10.1109/IS3C.2014.47},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06845479.pdf:pdf},
isbn = {9781479952779},
keywords = {bird species identification,color histogram,image feature analysis,image feature selection,image similarity},
mendeley-groups = {Dissertation},
pages = {139--142},
title = {{Research and Application of Bird Species Identification Algorithm Based on Image Features}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6845479},
year = {2014}
}
@article{Lee2008,
abstract = {This paper presents a method for automatic classification of birds into different species based on the audio recordings of their sounds. Each individual syllable segmented from continuous recordings is regarded as the basic recognition unit. To represent the temporal variations as well as sharp transitions within a syllable, a feature set derived from static and dynamic two-dimensional Mel-frequency cepstral coefficients are calculated for the classification of each syllable. Since a bird might generate several types of sounds with variant characteristics, a number of representative prototype vectors are used to model different syllables of identical bird species. For each bird species, a model selection method is developed to determine the optimal mode between Gaussian mixture models (GMM) and vector quantization (VQ) when the amount of training data is different for each species. In addition, a component number selection algorithm is employed to find the most appropriate number of components of GMM or the cluster number of VQ for each species. The mean vectors of GMM or the cluster centroids of VQ will form the prototype vectors of a certain bird species. In the experiments, the best classification accuracy is 84.06\% for the classification of 28 bird species.},
author = {Lee, Chang-Hsing and Han, Chin-Chuan and Chuang, Ching-Chien},
doi = {10.1109/TASL.2008.2005345},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/04648921.pdf:pdf},
isbn = {1558-7916},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
mendeley-groups = {Dissertation},
number = {8},
pages = {1541--1550},
title = {{Automatic Classification of Bird Species From Their Sounds Using Two-Dimensional Cepstral Coefficients}},
volume = {16},
year = {2008}
}
@article{Lee2013,
abstract = {Traditional birdsong recognition approaches used acoustic features based on the acoustic model of speech production or the perceptual model of the human auditory system to identify the associated bird species. In this paper, a new feature descriptor that uses image shape features is proposed to identify bird species based on the recognition of fixed-duration birdsong segments where their corresponding spectrograms are viewed as gray-level images. The MPEG-7 angular radial transform (ART) descriptor, which can compactly and efficiently describe the gray-level variations within an image region in both angular and radial directions, will be employed to extract the shape features from the spectrogram image. To effectively capture both frequency and temporal variations within a birdsong segment using ART, a sector expansion algorithm is proposed to transform its spectrogram image into a corresponding sector image such that the frequency and temporal axes of the spectrogram image will align with the radial and angular directions of the ART basis functions, respectively. For the classification of 28 bird species using Gaussian mixture models (GMM), the best classification accuracy is 86.30\% and 94.62\% for 3-second and 5-second birdsong segments using the proposed ART descriptor, which is better than traditional descriptors such as LPCC, MFCC, and TDMFCC.},
author = {Lee, Chang-Hsing and Hsu, Sheng-Bin and Shih, Jau-Ling and Chou, Chih-Hsun},
doi = {10.1109/TMM.2012.2229969},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06362230.pdf:pdf},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
mendeley-groups = {Dissertation},
number = {2},
pages = {454--464},
title = {{Continuous Birdsong Recognition Using Gaussian Mixture Modeling of Image Shape Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6362230},
volume = {15},
year = {2013}
}
@article{Li2012,
abstract = {In music information retrieval (MIR) an important research topic, which has attracted much attention recently, is the utilization of user-assigned tags, artist-related style, and mood labels, which can be extracted from music listening web sites, such as Last.fm (http://www.last.fm/) and All Music Guide (http://www.allmusic.com/). A fundamental research problem in the area is how to understand the relationships among artists/songs and these different pieces of information. Co-clustering is the problem of simultaneously clustering two types of data (e.g., documents and words, and webpages and urls). We can naturally bring this idea to the situation at hand and consider clustering artists and tags together, artists and styles together, or artists and mood labels together. Once such co-clustering has been successfully completed, one can identify co-existing clusters of artists and tags, styles, or mood labels (T/S/M). For simplicity, we use the acronym T/S/M to refer to tag(s), style(s), or mood(s) for the rest of the paper. When dealing with tags it is worth noticing that some tags are more specific versions of others. This naturally suggests that the tags could be organized in hierarchical clusters. Such hierarchical organizations exist for styles and mood labels, so we will consider hierarchical co-clustering of artists and T/S/M. In this paper, we systematically study the application of hierarchical co-clustering (HCC) methods for organizing the music data. There are two standard strategies for hierarchical clustering. One is the divisive strategy, in which we attempt to divide the input data set into smaller groups recursively, and the other is the agglomerative strategy, in which we attempt to combine initially individually separated data points into larger groups by finding the most closely related pair at each iteration. We will compare these two strategies against each other. We apply a previously known divisive hierarchical co-clustering method and a novel a- glomerative hierarchical co-clustering. In addition, we demonstrate that these two methods have the capability of incorporating instance-level constraints to achieve better performance. We perform experiments to show that these two hierarchical co-clustering methods can be effectively deployed for organizing the music data and they present reasonable clustering performance comparing with the other clustering methods. A case study is also conducted to show that HCC provides us a new method to quantify the artist similarity.},
author = {Li, Jingxuan and Shao, Bo and Li, Tao and Ogihara, Mitsunori},
doi = {10.1109/TMM.2011.2181151},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06111486.pdf:pdf},
isbn = {1520-9210},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Co-clustering,hierarchical clustering,user tags},
mendeley-groups = {Dissertation},
number = {2},
pages = {471--481},
title = {{Hierarchical co-clustering: A new way to organize the music data}},
volume = {14},
year = {2012}
}
@article{Li2014,
author = {Li, Wen and Song, Dezhen},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06481468.pdf:pdf},
mendeley-groups = {Dissertation},
number = {2},
pages = {348--358},
title = {{Automatic Bird Species Detection From}},
volume = {11},
year = {2014}
}
@article{Lopes2011,
abstract = {In this paper we focus on the automatic identification of bird species from their audio recorded song. Bird monitoring is important to perform several tasks, such as to evaluate the quality of their living environment or to monitor dangerous situations to planes caused by birds near airports. We deal with the bird species identification problem using signal processing and machine learning techniques. First, features are extracted from the bird recorded songs using specific audio treatment, next the problem is performed according to a classical machine learning scenario, where a labeled database of previously known bird songs are employed to create a decision procedure that is used to predict the species of a new bird song. Experiments are conducted in a dataset of recorded songs of bird species which appear in a specific region. The experimental results compare the performance obtained in different situations, encompassing the complete audio signals, as recorded in the field, and short audio segments (pulses) obtained from the signals by a split procedure. The influence of the number of classes (bird species) in the identification accuracy is also evaluated.},
author = {Lopes, Marcelo T. and Gioppo, Lucas L. and Higushi, Thiago T. and a.a. Kaestner, Celso and Jr., Carlos N. Silla and Koerich, Alessandro L.},
doi = {10.1109/ISM.2011.27},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06123334.pdf:pdf},
isbn = {978-0-7695-4589-9},
journal = {2011 IEEE International Symposium on Multimedia},
keywords = {bird species identification,machine learning,pattern recognition,signal processing},
mendeley-groups = {Dissertation},
pages = {117--122},
title = {{Automatic Bird Species Identification for Large Number of Species}},
year = {2011}
}
@article{Lopes2011a,
abstract = {This paper deals with the automated bird species identification problem, in which it is necessary to identify the species of a bird from its audio recorded song. This is a clever way to monitor biodiversity in ecosystems, since it is an indirect non-invasive way of evaluation. Different features sets which summarize in different aspects the audio properties of the audio signal are evaluated in this paper together with machine learning algorithms, such as probabilistic, instance-based, decision trees, neural networks and support vector machines. Experiments are conducted in a dataset of recorded songs of three bird species. The experimental results compare the performance of the features sets and different classifiers showing that it is possible to obtain very promising results in the automated bird species identification problem.},
author = {Lopes, Marcelo Teider and Silla, Carlos Nascimento and Koerich, Alessandro Lameiras and Kaestner, Celso Antonio Alves},
doi = {10.1109/ICSMC.2011.6083794},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06083794.pdf:pdf},
isbn = {9781457706523},
issn = {1062922X},
journal = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
keywords = {bird species identification,machine learning,pattern recognition,signal processing},
mendeley-groups = {Dissertation},
pages = {965--970},
title = {{Feature set comparison for automatic bird species identification}},
year = {2011}
}
@article{Marini2013,
author = {Marini, Andreia and Facon, Jacques and Koerich, Alessandro L.},
doi = {10.1109/SMC.2013.740},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06722493.pdf:pdf},
isbn = {978-1-4799-0652-9},
journal = {2013 IEEE International Conference on Systems, Man, and Cybernetics},
mendeley-groups = {Dissertation},
pages = {4336--4341},
title = {{Bird Species Classification Based on Color Features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6722493},
year = {2013}
}
@article{McIlraith1995,
abstract = {Analysis of speech often begins with study of the vocal tract that
created it. Bird vocalizations and human speech are generated by similar
processes. This suggests that LPC coefficients extracted from birdsong
samples could retain enough information to permit identification of
species. In this paper we train a back-propagation neural network to
recognize bird songs. We generated test and training data sets using 133
songs from six common bird species. Initially, identification
performance was good for some species, and poor for others. We
attributed this to a lack of temporal context information in the data.
By changing the type of spectral information presented to the network,
we were able to improve performance. We conclude that a neural network
combined with digital preprocessing can be used to identify a bird by
its song},
author = {a.L. McIlraith and Card, H.C.},
doi = {10.1109/WESCAN.1995.494065},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/00494065.pdf:pdf},
isbn = {0-7803-2725-X},
journal = {IEEE WESCANEX 95. Communications, Power, and Computing. Conference Proceedings},
keywords = {abstract analysis of speech,artificial neural networks,birdsong,lpc analysis,often begins w,processing,speech recognition,temporal},
mendeley-groups = {Dissertation},
number = {95},
title = {{Birdsong recognition with DSP and neural networks}},
volume = {2},
year = {1995}
}
@book{Moses2004,
author = {Moses, Petre Stoica and Randolph},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/signals/SAS-new.pdf:pdf},
isbn = {0131139568},
mendeley-groups = {Dissertation},
title = {{Spectral Analysis of Signals}},
year = {2004}
}
@article{Pang2014,
author = {Pang, Cheng and Yao, Hongxun and Sun, Xiaoshuai},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/p256-pang.pdf:pdf},
isbn = {9781450328104},
keywords = {bird species classification,discriminative features,fine-,grained classification},
mendeley-groups = {Dissertation},
title = {{Discriminative Features for Bird Species Classification}},
year = {2014}
}
@article{Selouani2005,
abstract = {A template-based technique for automatic recognition of birdsong syllables is presented. This technique combines time delay neural networks (TDNNs) with an autoregressive (AR) version of the backpropagation algorithm in order to improve the accuracy of bird species identification. The proposed neural network structure (AR-TDNN) has the advantage of dealing with a pattern classification of syllable alphabet and also of capturing the temporal structure of birdsong. We choose to carry out trials on song patterns obtained from sixteen species living in New Brunswick province of Canada. The results show that the proposed AR-TDNN system achieves a highly recognition rate compared to the baseline backpropagation-based system},
author = {Selouani, S.-a. and Kardouchi, M. and Hervet, E. and Roy, D.},
doi = {10.1109/CIMA.2005.1662316},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/01662316.pdf:pdf},
isbn = {1-4244-0020-1},
journal = {2005 ICSC Congress on Computational Intelligence Methods and Applications},
mendeley-groups = {Dissertation},
pages = {1--6},
title = {{Automatic birdsong recognition based on autoregressive time-delay neural networks}},
year = {2005}
}
@article{Silla2013,
abstract = {In this paper we address the task of hierarchical bird species identification from audio recordings. We evaluate three types of approaches to deal with hierarchical classification problems: the flat classification approach, the local-model per parent node classifier approach and the global-model hierarchical-classification approach. For the flat and local-model classification approach we employ the classic Naive Bayes algorithm. For the global-model approach we use the Global Model Naive Bayes (GMNB) algorithm. As in the classical Naive Bayes, the algorithm computes prior probabilities and likelihoods, but these computations take into account the hierarchical classification scenario: it assumes that any example which belongs to a given class will also belong to all its ancestor classes. In the current application, the employed class hierarchy is the standard scientific taxonomy of birds used in Biology. In order to deal with the bird songs we obtain features by computing several acoustic quantities from intervals of the audio signal. We conduct three experiments in order to compare the three different approaches to the hierarchical bird species identification problem. Our experimental results show that the use of the GMNB hierarchical classification algorithm outperforms both the flat and local-model approaches (Using the Hierarchical F-measure metric), hence the use of a global-model approach (such as the GMNB) can be a feasible way to improve the classification performance for problems with a large number of classes.},
author = {Silla, Carlos N. and a.a. Kaestner, Celso},
doi = {10.1109/SMC.2013.326},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06722079.pdf:pdf},
isbn = {978-1-4799-0652-9},
journal = {2013 IEEE International Conference on Systems, Man, and Cybernetics},
mendeley-groups = {Dissertation},
number = {1},
pages = {1895--1900},
title = {{Hierarchical Classification of Bird Species Using Their Audio Recorded Songs}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6722079},
year = {2013}
}
@article{Wielgat2012,
author = {Wielgat, Robert and Potempa, Tomasz and Swietojanski, Pawel and Krol, Daniel},
doi = {10.1109/ICSES.2012.6382258},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/06382258.pdf:pdf},
isbn = {9781467317092},
journal = {2012 International Conference on Signals and Electronic Systems, ICSES 2012 - The Conference Proceedings},
mendeley-groups = {Dissertation},
title = {{On using prefiltration in HMM-based bird species recognition}},
year = {2012}
}
@article{Awatade2012,
author = {Awatade, Manisha H},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/ncipet1012.pdf:pdf},
keywords = {formant,linear prediction coding,model matching,tracking},
mendeley-groups = {Dissertation},
pages = {14--17},
title = {{Theoretical Survey of the Formant Tracking Algorithm}},
year = {2012}
}
@article{Botev2010,
abstract = {We present a new adaptive kernel density estimator based on linear diffusion processes. The proposed estimator builds on existing ideas for adaptive smoothing by incorporating information from a pilot density estimate. In addition, we propose a new plug-in bandwidth selection method that is free from the arbitrary normal reference rules used by existing methods. We present simulation examples in which the proposed approach outperforms existing methods in terms of accuracy and reliability.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.2602v1},
author = {Botev, Z. I. and Grotowski, J. F. and Kroese, D. P.},
doi = {10.1214/10-AOS799},
eprint = {arXiv:1011.2602v1},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/kde/via diffusion.pdf:pdf},
isbn = {0090-5364},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bandwidth selection,Boundary bias,Data sharpening,Diffusion equation,Heat kernel,Langevin process,Nonparametric density estimation,Normal reference rules,Variable bandwidth},
mendeley-groups = {Dissertation},
number = {5},
pages = {2916--2957},
title = {{Kernel density estimation via diffusion}},
volume = {38},
year = {2010}
}
@article{Coates2012,
author = {Coates, Adam and Ng, Andrew Y},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/spherical\_kmeans.pdf:pdf},
mendeley-groups = {Dissertation},
pages = {561--580},
title = {{Learning Feature Representations with K-Means}},
year = {2012}
}
@article{Ganapathy2012,
author = {Ganapathy, Sriram},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/HIlbertLPC.pdf:pdf},
mendeley-groups = {Dissertation},
title = {{Signal Analysis Using Autoregressive Models}},
year = {2012}
}
@article{Montavon2009,
author = {Montavon, Gregoire},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/montavon-paper.pdf:pdf},
journal = {Deep Learning for Speech Recognition and Related Applications, NIPS 2009},
mendeley-groups = {Dissertation},
pages = {1--4},
title = {{Deep learning for spoken language identification}},
year = {2009}
}
@article{Rezek2005,
abstract = {Hidden Markov Models (HMM) have proven to be very useful in a
  variety of biomedical applications. The most established method for
  estimating HMM parameters is the maximum likelihood method which has
  shortcomings, such as repeated estimation and penalisation of the
  likelihood score, that are well known. This paper describes an
  Variational learning approach to try and improve on the
  maximum-likelihood estimators. Emphasis lies on the fact, that for
  HMMs with observation models that are from the exponential family of
  distributions, all HMM parameters and hidden state variables can be
  derived from a single loss function, namely the Kullback-Leibler
  Divergence. Practical issues, such as model initialisation and choice
  of model order, are described. The paper concludes by application of
  3 types of observation model HMMs to a variety of biomedical data,
  such as EEG and ECG, from different physiological experiments and
  conditions.},
author = {Rezek, Iead and Roberts, Stephen J.},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/varhmm.pdf:pdf},
keywords = {Brain Computer Interfaces,Computational, Information-Theoretic Learning with},
mendeley-groups = {Dissertation},
title = {{Ensemble Hidden Markov Models with Extended Observation Densities for Biosignal Analysis}},
url = {http://eprints.pascal-network.org/archive/00001124/},
year = {2005}
}
@article{Roberts1997,
abstract = {Much work has been published on methods for assessing the probable$\backslash$nnumber of clusters or structures within unknown data sets. This paper$\backslash$naims to look in more detail at two methods, a broad parametric method,$\backslash$nbased around the assumption of Gaussian clusters and the other a$\backslash$nnon-parametric method which utilises methods of scale-space filtering$\backslash$nto extract robust structures within a data set. It is shown that,$\backslash$nwhilst both methods are capable of determining cluster validity for$\backslash$ndata sets in which clusters tend towards a multivariate Gaussian$\backslash$ndistribution, the parametric method inevitably fails for clusters$\backslash$nwhich have a non-Gaussian structure whilst the scale-space method$\backslash$nis more robust.},
author = {Roberts, Stephen J.},
doi = {10.1016/S0031-3203(96)00079-9},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/cluster.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {bility density estimation,cluster analysis,maximum likelihood methods,proba-,scale-space ltering},
mendeley-groups = {Dissertation},
number = {2},
pages = {261--272},
title = {{Parametric and non-parametric unsupervised cluster analysis}},
volume = {30},
year = {1997}
}
@article{RobertsStephenJ.;EversonRichard;Rezek1997,
author = {{Roberts, Stephen J.; Everson, Richard; Rezek}, Iead},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/minent\_icann99.pdf:pdf},
mendeley-groups = {Dissertation},
title = {{Minimum Entropy Data Partitioning}},
year = {1997}
}
@misc{Roberts2000,
author = {Roberts, Stephen J. and Holmes, Chris and Denison, Dave},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/rjclust\_v2.pdf:pdf},
mendeley-groups = {Dissertation},
title = {{Minimum-Entropy Data Partitioning using Reversible Jump Markov Chain Monte Carlo}},
year = {2000}
}
@article{Stowell2013,
abstract = {Birdsong often contains large amounts of rapid frequency modulation (FM). It is believed that the use or otherwise of FM is adaptive to the acoustic environment, and also that there are specific social uses of FM such as trills in aggressive territorial encounters. Yet temporal fine detail of FM is often absent or obscured in standard audio signal analysis methods such as Fourier analysis or linear prediction. Hence it is important to consider high resolution signal processing techniques for analysis of FM in bird vocalisations. If such methods can be applied at big data scales, this offers a further advantage as large datasets become available. We introduce methods from the signal processing literature which can go beyond spectrogram representations to analyse the fine modulations present in a signal at very short timescales. Focusing primarily on the genus Phylloscopus, we investigate which of a set of four analysis methods most strongly captures the species signal encoded in birdsong. In order to find tools useful in practical analysis of large databases, we also study the computational time taken by the methods, and their robustness to additive noise and MP3 compression. We find three methods which can robustly represent species-correlated FM attributes, and that the simplest method tested also appears to perform the best. We find that features representing the extremes of FM encode species identity supplementary to that captured in frequency features, whereas bandwidth features do not encode additional information. Large-scale FM analysis can efficiently extract information useful for bioacoustic studies, in addition to measures more commonly used to characterise vocalisations.},
archivePrefix = {arXiv},
arxivId = {1311.4764},
author = {Stowell, Dan and Plumbley, Mark D},
doi = {10.1111/2041-210X.12223},
eprint = {1311.4764},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/mee312223.pdf:pdf},
issn = {2041210X},
mendeley-groups = {Dissertation},
pages = {1--22},
title = {{Large-scale analysis of frequency modulation in birdsong databases}},
url = {http://arxiv.org/abs/1311.4764},
year = {2013}
}
@article{Stowell2014,
abstract = {Automatic species classification of birds from their sound is a computational tool of increasing importance in ecology, conservation monitoring and vocal communication studies. To make classification useful in practice, it is crucial to improve its accuracy while ensuring that it can run at big data scales. Many approaches use acoustic measures based on spectrogram-type data, such as the Mel-frequency cepstral coefficient (MFCC) features which represent a manually-designed summary of spectral information. However, recent work in machine learning has demonstrated that features learnt automatically from data can often outperform manually-designed feature transforms. Feature learning can be performed at large scale and "unsupervised", meaning it requires no manual data labelling, yet it can improve performance on "supervised" tasks such as classification. In this work we introduce a technique for feature learning from large volumes of bird sound recordings, inspired by techniques that have proven useful in other domains. We experimentally compare twelve different feature representations derived from the Mel spectrum (of which six use this technique), using four large and diverse databases of bird vocalisations, with a random forest classifier. We demonstrate that MFCCs are of limited power in this context, leading to worse performance than the raw Mel spectral data. Conversely, we demonstrate that unsupervised feature learning provides a substantial boost over MFCCs and Mel spectra without adding computational complexity after the model has been trained. The boost is particularly notable for single-label classification tasks at large scale. The spectro-temporal activations learned through our procedure resemble spectro-temporal receptive fields calculated from avian primary auditory forebrain.},
archivePrefix = {arXiv},
arxivId = {1405.6524},
author = {Stowell, Dan and Plumbley, Mark D.},
doi = {10.7717/peerj.488},
eprint = {1405.6524},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/stowell\_chapter.pdf:pdf},
issn = {2167-8359},
journal = {PeerJ},
keywords = {accepted 26 june 2014,bioacoustics,birds,birdsong,classification,machine learning,published 17 july 2014,submitted 25 may 2014,vocalisation},
mendeley-groups = {Dissertation},
pages = {e488; DOI 10.7717/peerj.488},
pmid = {25083350},
title = {{Automatic large-scale classification of bird sounds is strongly improved by unsupervised feature learning}},
url = {https://peerj.com/articles/488},
volume = {2},
year = {2014}
}
@article{Araujo1998,
abstract = {This paper presents an algorithm for F1 and F2 formant estimation.
The proposed algorithm combines a linear predictive analysis together
with the Mel psychoacoustical perceptual scale. The algorithm was tested
for the first 2 formants and produced good performance for male and
female speakers, adults and children. In contrast to the classical LPC
algorithm which requires variable-order prediction filters to take into
account different formant patterns, the proposed algorithm is capable of
extracting these formants with a fixed-order prediction filter},
author = {Araujo, a.M. De Lima and Violaro, F.},
doi = {10.1109/ITS.1998.713118},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/formants/from\_mfcc.pdf:pdf},
isbn = {0-7803-5030-8},
journal = {ITS'98 Proceedings. SBT/IEEE International Telecommunications Symposium (Cat. No.98EX202)},
mendeley-groups = {Dissertation},
number = {l},
title = {{Formant frequency estimation using a Mel-scale LPC algorithm}},
year = {1998}
}
@article{Darch,
abstract = {This work proposes a novel method of predicting formant frequencies from a stream of mel-frequency cepstral coefficients (MFCC) feature vectors. Prediction is based on modelling the joint density of MFCC vectors and formant vectors using a Gaussian mixture model (GMM). Using this GMM and an input MFCC vector, two maximum a posteriori (MAP) prediction methods are developed. The first method predicts formants from the closest, in some sense, cluster to the input MFCC vector, while the second method takes a weighted contribution of formants from all clusters. Experimental results are presented using the ETSI Aurora connected digit database and show that the predicted formant frequency is within 3.25\% of the reference formant frequency, as measured from hand-corrected formant tracks.},
author = {Darch, Jonathan and Milner, Ben and Shao, Xu},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/Darch, Milner, Shao - Unknown - Formant Prediction from MFCC Vectors.pdf:pdf},
mendeley-groups = {Dissertation},
title = {{Formant Prediction from MFCC Vectors}}
}
@article{Holmes1895,
author = {Holmes, John N and Holmes, Wendy J and Garner, Philip N},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/formants/in\_speech\_rec.pdf:pdf},
mendeley-groups = {Dissertation},
number = {1},
pages = {4--7},
title = {{Using Formant Frequencies in Speech recognition}},
year = {1895}
}
@article{Koops2014,
author = {Koops, Hendrik Vincent},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/deep\_learning\_birdsong.pdf:pdf},
mendeley-groups = {Dissertation},
number = {July},
title = {{A Deep Neural Network Approach to Automatic Birdsong Recognition}},
year = {2014}
}
@article{Prahallad,
author = {Prahallad, Kishore},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/mfcc/03\_mfcc.pdf:pdf},
journal = {Technology},
mendeley-groups = {Dissertation},
pages = {1--50},
title = {{Speech Technology : A Practical Introduction Topic : Spectrogram , Cepstrum and Mel-Frequency Analysis Mel-Frequency Analysis Mel-Frequency Cepstral Coefficients}}
}
@article{Welling1998,
abstract = {This paper presents a new method for estimating formant
frequencies. The formant model is based on a digital resonator. Each
resonator represents a segment of the short-time power spectrum. The
complete spectrum is modeled by a set of digital resonators connected in
parallel. An algorithm based on dynamic programming produces both the
model parameters and the segment boundaries that optimally match the
spectrum. We used this method in experimental tests that were carried
out on the TI digit string data base. The main results of the
experimental tests are: (1) the presented approach produces reliable
estimates of formant frequencies across a wide range of sounds and
speakers; and (2) the estimated formant frequencies were used in a
number of variants for recognition. The best set-up resulted in a string
error rate of 4.2\% on the adult corpus of the TI digit string data base
},
author = {Welling, Lutz and Ney, Hermann},
doi = {10.1109/89.650308},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/10.1.1.310.2062.pdf:pdf},
issn = {10636676},
journal = {IEEE Transactions on Speech and Audio Processing},
keywords = {Formants,Linear prediction,Speech analysis,Speech recognition},
mendeley-groups = {Dissertation},
number = {1},
pages = {36--48},
title = {{Formant estimation for speech recognition}},
volume = {6},
year = {1998}
}
@article{Madani,
author = {Madani, Omid and Connor, Michael},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/largescaleclassification.pdf:pdf},
mendeley-groups = {Dissertation},
pages = {846--857},
title = {{Large-Scale Many-Class Learning}}
}
@article{Sun,
author = {Sun, Chong and Rampalli, Narasimhan and Yang, Frank and Doan, Anhai},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/chimera-vldb14.pdf:pdf},
mendeley-groups = {Dissertation},
title = {{Chimera : Large-Scale Classification using Machine Learning , Rules , and Crowdsourcing}}
}
@article{Kasprzak2006,
author = {Kasprzak, Wlodzimierz and Okazaki, Adam F and Kowalski, Adam B},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/ICA06.pdf:pdf},
mendeley-groups = {Dissertation},
pages = {609--616},
title = {{ICA-Based Speech Features in the Frequency Domain}},
year = {2006}
}
@article{Weston2014,
author = {Weston, Jason},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/many class classifiers gupta14a.pdf:pdf},
keywords = {classification,large-scale,multiclass,online learning,stochastic gradient},
mendeley-groups = {Dissertation},
pages = {1461--1492},
title = {{Training Highly Multiclass Classifiers}},
volume = {15},
year = {2014}
}
@article{Hyvarinen2000,
author = {Hyv\"{a}rinen, Aapo and Oja, Erkki},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/ICA.pdf:pdf},
keywords = {analysis,blind signal separation,factor,independent component analysis,projection pursuit,representation,source separation},
mendeley-groups = {Dissertation},
number = {1},
title = {{Independent Component Analysis : Algorithms and Applications}},
volume = {1},
year = {2000}
}
@article{Psorakis2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1009.2646v5},
author = {Psorakis, Ioannis and Roberts, Stephen and Sheldon, Ben},
eprint = {arXiv:1009.2646v5},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/EfficientCommunityDetection.pdf:pdf},
keywords = {bayesian inference,community detection,non-negative matrix factorisation},
mendeley-groups = {Dissertation},
pages = {1--18},
title = {{Efficient Bayesian Community Detection using Non-negative Matrix}},
year = {2010}
}
@article{Psorakis2012,
author = {Psorakis, Ioannis and Roberts, Stephen J and Rezek, Iead and Sheldon, Ben C},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/EcologicalSocialNetworks.pdf:pdf},
keywords = {animal social networks,network analysis,spatio-temporal data streams},
mendeley-groups = {Dissertation},
title = {{Inferring social network structure in ecological systems from spatio- temporal data streams}},
year = {2012}
}
@article{Sheldon,
author = {Sheldon, Ben},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/CommunityDetection.pdf:pdf},
mendeley-groups = {Dissertation},
title = {{Overlapping Community Detection using Bayesian Nonnegative Matrix Factorization}}
}
@article{Kim2008,
abstract = {Many papers published in recent years show that real-world graphs G (n, m) (n nodes, m edges) are more or less "complex" in the sense that different topological features deviate from random graphs. Here we narrow the definition of graph complexity and argue that a complex graph contains many different subgraphs. We present different measures that quantify this complexity, for instance C1 e, the relative number of non-isomorphic one-edge-deleted subgraphs (i.e.??DECK size). However, because these different subgraph measures are computationally demanding, we also study simpler complexity measures focussing on slightly different aspects of graph complexity. We consider heuristically defined "product measures", the products of two quantities which are zero in the extreme cases of a path and clique, and "entropy measures" quantifying the diversity of different topological features. The previously defined network/graph complexity measures Medium Articulation and Offdiagonal complexity (OdC) belong to these two classes. We study OdC measures in some detail and compare it with our new measures. For all measures, the most complex graph GCmax has a medium number of edges, between the edge numbers of the minimum and the maximum connected graph n - 1 < m (GCmax) < n (n - 1) / 2. Interestingly, for some measures over(C, ??) this number scales exactly with the geometric mean of the extremes: m (Gover(C, ??)max) = sqrt(n / 2) (n - 1) ??? n1.5. All graph complexity measures are characterized with the help of different example graphs. For all measures the corresponding time complexity is given. Finally, we discuss the complexity of 33 real-world graphs of different biological, social and economic systems with the six computationally most simple measures (including OdC). The complexities of the real graphs are compared with average complexities of two different random graph versions: complete random graphs (just fixed n, m) and rewired graphs with fixed node degrees. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {Kim, Jongkwang and Wilhelm, Thomas},
doi = {10.1016/j.physa.2008.01.015},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/1-s2.0-S0378437108000319-main.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Complexity,Graph,Network},
mendeley-groups = {Dissertation},
number = {11},
pages = {2637--2652},
title = {{What is a complex graph?}},
volume = {387},
year = {2008}
}
@book{Bishop2006,
address = {Cambridge},
author = {Bishop, Christopher},
mendeley-groups = {Dissertation},
publisher = {Springer},
title = {{Pattern Recognition and Machine Learning}},
year = {2006}
}
@book{Naguib2014a,
author = {Naguib, Marc and Riebel, Katharina},
doi = {10.1007/978-94-007-7414-8},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/birdsong/bok\%3A978-94-007-7414-8.pdf:pdf},
isbn = {978-94-007-7413-1},
mendeley-groups = {Dissertation},
pages = {233--247},
title = {{Biocommunication of Animals}},
url = {http://link.springer.com/10.1007/978-94-007-7414-8},
year = {2014}
}
@book{Santosh2013,
author = {Santosh, a. and Helekar},
doi = {10.1007/978-1-4614-8400-4},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/birdsong/bok\%3A978-1-4614-8400-4.pdf:pdf},
isbn = {978-1-4614-8399-1},
mendeley-groups = {Dissertation},
title = {{Animal Models of Speech and Language Disorders}},
url = {http://link.springer.com/10.1007/978-1-4614-8400-4},
year = {2013}
}
@article{Snowdon2013,
author = {Snowdon, Charles T},
doi = {10.1007/978-1-4614-8400-4},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/birdsong/chp\%3A10.1007\%2F978-1-4614-8400-4\_4.pdf:pdf},
isbn = {978-1-4614-8399-1},
keywords = {1202 west johnson street,babbling,c,cognition,d,department of psychology,madison,new world primates,ph,referential signals,snowdon,syntax,t,university of wisconsin,vocal complexity,vocal control},
mendeley-groups = {Dissertation},
pages = {241--261},
title = {{Animal Models of Speech and Language Disorders}},
url = {http://link.springer.com/10.1007/978-1-4614-8400-4},
year = {2013}
}
@article{Naguib2014,
author = {Naguib, Marc and Riebel, Katharina},
doi = {10.1007/978-94-007-7414-8},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/birdsong/chp\%3A10.1007\%2F978-94-007-7414-8\_13.pdf:pdf},
isbn = {978-94-007-7413-1},
mendeley-groups = {Dissertation},
pages = {233--247},
title = {{Biocommunication of Animals}},
url = {http://link.springer.com/10.1007/978-94-007-7414-8},
year = {2014}
}
@article{Cate2004,
abstract = {Bird species differ greatly in their songs. A full understanding of the evolution of this variety requires us to combine the study of selection and phylogeny with that of the mechanisms involved in their production and perception. This requirement is not unique to the study of vocal signals, but can be extended to evolution of signals in general. The vocal signals of birds, however, offer especially attractive model systems for such studies. This is so, not just because many aspects of bird vocalizations-their communicative significance, their development, their production, and perception are amenable to study in great detail-but also because of their intrinsic attractiveness to us as human listeners. ?? 2004 Elsevier Inc. All rights reserved.},
author = {Cate, Carel Ten},
doi = {10.1016/B978-012473070-0/50013-X},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/birdsong/birdsong\_evolution.pdf:pdf},
isbn = {9780124730700},
journal = {Nature's Music: The Science of Birdsong},
mendeley-groups = {Dissertation},
pages = {296--317},
title = {{Birdsong and evolution}},
year = {2004}
}
@book{Marler2004,
address = {Amsterdam},
annote = {Accession Number: 189483. Publication Type: eBook. Language: English.},
author = {Marler, Peter and Slabbekoorn, Hans Willem},
isbn = {9780124730700},
keywords = {Birds--Behavior,Birds--Vocalization,Birdsongs,MEDICAL / Neuroscience,NATURE / Birdwatching Guides,SCIENCE / Life Sciences / Zoology / General},
mendeley-groups = {Dissertation/BirdsongFeatures,Dissertation},
publisher = {Academic Press},
title = {{Nature's Music : The Science of Birdsong}},
url = {http://search.ebscohost.com/login.aspx?direct=true\&db=nlebk\&AN=189483\&site=ehost-live},
year = {2004}
}
@book{Berwick2013,
address = {Cambridge, Mass.},
annote = {Includes bibliographical references and index.},
editor = {Berwick, Robert C and Bolhuis, Johan J and Chomsky, Noam and Everaert, Martin and Ebrary, Inc},
keywords = {Birds -- Vocalization,Birdsongs,Cognitive neuroscience,Human evolution,Language acquisition,Neurolinguistics,Speech acts (Linguistics)},
language = {eng},
mendeley-groups = {Dissertation/BirdsongFeatures},
publisher = {Cambridge, Mass. : MIT Press},
title = {{Birdsong, speech, and language [electronic resource] : exploring the evolution of mind and brain}},
year = {2013}
}
@article{Cooley1965,
author = {Cooley, J W and Tukey, J W},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/S0025-5718-1965-0178586-1.pdf:pdf},
journal = {Mathematics of Computation},
mendeley-groups = {Dissertation},
pages = {297},
title = {{An Algorithm for the Machine Computation of the Complex Fourier Series}},
volume = {19},
year = {1965}
}
@misc{Smith2011,
author = {Smith, Steven W.},
booktitle = {Digital Signal Processing},
mendeley-groups = {Dissertation},
title = {{The Fast Fourier Transform}},
url = {http://www.dspguide.com/ch12/2.htm},
urldate = {August 6th 2015},
year = {2011}
}
@misc{Weisstein2015,
author = {Weisstein, Eric E},
booktitle = {Wolfram Mathworld},
mendeley-groups = {Dissertation},
title = {{Fourier Transform}},
url = {http://mathworld.wolfram.com/FourierTransform.html},
year = {2015}
}
@misc{Weisstein2015,
author = {Weisstein, Eric W.},
booktitle = {Wolfram Alpha},
mendeley-groups = {Dissertation},
title = {{Danielson-Lanczos Lemma}},
url = {http://mathworld.wolfram.com/Danielson-LanczosLemma.html},
year = {2015}
}
@article{Sludge2000,
author = {Sludge, Activated},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/MFCC\_worksheet.pdf:pdf},
mendeley-groups = {Dissertation},
number = {2},
pages = {1--6},
title = {The mel frequency scale and coefficient},
volume = {1},
year = {2000}
}
@misc{Gutierrez-Osuna2009,
author = {Guti\'{e}rrez-Osuna, Ricardo},
mendeley-groups = {Dissertation/BirdsongFeatures},
title = {{Cepstral Analysis}},
url = {http://research.cs.tamu.edu/prism/lectures/sp/l9.pdf},
urldate = {August 6th 2015},
year = {2009}
}
@book{Jurafsky2009,
author = {Jurafsky, Daniel and Martin, James H.},
edition = {2},
mendeley-groups = {Dissertation/BirdsongFeatures},
title = {{Speech and Language Processing}},
year = {2009}
}
@article{Muda2010,
abstract = {Digital processing of speech signal and voice recognition algorithm is very important for fast and accurate automatic voice recognition technology. The voice is a signal of infinite information. A direct analysis and synthesizing the complex voice signal is due to too much information contained in the signal. Therefore the digital signal processes such as Feature Extraction and Feature Matching are introduced to represent the voice signal. Several methods such as Liner Predictive Predictive Coding (LPC), Hidden Markov Model (HMM), Artificial Neural Network (ANN) and etc are evaluated with a view to identify a straight forward and effective method for voice signal. The extraction and matching process is implemented right after the Pre Processing or filtering signal is performed. The non-parametric method for modelling the human auditory perception system, Mel Frequency Cepstral Coefficients (MFCCs) are utilize as extraction techniques. The non linear sequence alignment known as Dynamic Time Warping (DTW) introduced by Sakoe Chiba has been used as features matching techniques. Since it's obvious that the voice signal tends to have different temporal rate, the alignment is important to produce the better performance.This paper present the viability of MFCC to extract features and DTW to compare the test patterns.},
archivePrefix = {arXiv},
arxivId = {1003.4083},
author = {Muda, Lindasalwa and Begam, Mumtaj and Elamvazuthi, I.},
eprint = {1003.4083},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/1003.4083.pdf:pdf},
mendeley-groups = {Dissertation/BirdsongFeatures},
number = {3},
pages = {138--143},
title = {{Voice Recognition Algorithms using Mel Frequency Cepstral Coefficient (MFCC) and Dynamic Time Warping (DTW) Techniques}},
url = {http://arxiv.org/abs/1003.4083},
volume = {2},
year = {2010}
}
@misc{Prahallad2011,
author = {Prahallad, Kishore},
mendeley-groups = {Dissertation/BirdsongFeatures},
title = {{Spectrogram, Cepstrum and Mel-Frequency Analysis}},
url = {http://www.speech.cs.cmu.edu/15-492/slides/03\_mfcc.pdf},
year = {2011}
}
@misc{Lyons2014,
author = {Lyons, James},
mendeley-groups = {Dissertation},
title = {{Mel Frequency Cepstral Coefficient (MFCC) tutorial}},
url = {http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/},
year = {2014}
}
@article{Coates2012,
abstract = {Many algorithms are available to learn deep hierarchies of features from unlabeled data, especially images. In many cases, these algorithms involve multi-layered networks of features (e.g., neural net- works) that are sometimes tricky to train and tune and are difficult to scale up to many machines effectively. Recently, it has been found that K-means clustering can be used as a fast alternative training method. The main advantage of this approach is that it is very fast and easily implemented at large scale. On the other hand, employing this method in practice is not completely trivial: K-means has several limitations, and care must be taken to combine the right ingredients to get the system to work well. This chapter will summarize recent results and technical tricks that are needed to make effective use of K-means clustering for learning large-scale representations of images.We will also connect these results to other well-known algorithms to make clear when K-means can be most useful and convey intuitions about its behavior that are useful for debugging and engineering new systems. 1},
author = {Coates, Adam and Ng, Andrew Y.},
doi = {10.1007/978-3-642-35289-8-30},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/coatesng\_nntot2012.pdf:pdf},
isbn = {9783642352881},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {561--580},
title = {{Learning feature representations with K-means}},
volume = {7700 LECTURE NO},
year = {2012}
}
@article{Dieleman2013,
abstract = {Content-based music information retrieval tasks are typically solved with a two-stage approach: features are extracted from music audio signals, and are then used as input to a regressor or classifier. These features can be engineered or learned from data. Although the former approach was dominant in the past, feature learning has started to receive more attention from the MIR community in recent years. Recent results in feature learning indicate that simple algorithms such as K-means can be very effective, sometimes surpassing more complicated approaches based on restricted Boltzmann machines, autoencoders or sparse coding. Furthermore, there has been increased interest in multiscale representations of music audio recently. Such representations are more versatile because music audio exhibits structure on multiple timescales, which are relevant for different MIR tasks to varying degrees. We develop and compare three approaches to multiscale audio feature learning using the spherical K-means algorithm. We evaluate them in an automatic tagging task and a similarity metric learning task on the Magnatagatune dataset.},
author = {Dieleman, Sander and Schrauwen, Benjamin},
doi = {10.1109/IJCNN.2005.1556436},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/69\_Paper.pdf:pdf},
isbn = {0780390482},
journal = {Proceedings of the 14th international society for music information retrieval conference},
pages = {116--121},
title = {{Multiscale Approaches To Music Audio Feature Learning}},
url = {http://hdl.handle.net/1854/LU-4152117},
year = {2013}
}
@article{Vidakovic1991,
abstract = {Strictly speaking, wavelets are topic of pure mathematics, however in only a few years of existence as a theory of their own, they have shown great potential and applicability in many fields. There are several excellent monographs and articles talking about wavelets, and this modest tutorial does not intend to compete with any of them. Rather it is intended to serve as a very first reading, giving examples interesting for the statistical community. We also give references for further reading as well as some mathematica do-it-yourself procedures.},
author = {Vidakovic, Brani and Mueller, Peter},
doi = {10.1093/biomet/asq007},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/kidsA.pdf:pdf},
issn = {0006-3444},
journal = {Victoria},
mendeley-groups = {Dissertation/BirdsongFeatures},
pages = {1--35},
title = {{Wavelets for kids: A tutorial introduction}},
url = {http://en.scientificcommons.org/43330015},
year = {1991}
}
@article{Gamulkiewicz2003,
author = {Gamulkiewicz, Brian and Weeks, Michael},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/MWSCAS03\_speech.pdf:pdf},
journal = {IEEE Midwest Symposium on Circuits and Systems (MWSCAS)},
title = {{Wavelet Based Speech Recognition}},
year = {2003}
}
@misc{Garrett-Glaser2010,
author = {Garrett-Glaser, Jason},
booktitle = {Diary Of An x264 Developer},
mendeley-groups = {Dissertation},
title = {{The problems with wavelets}},
url = {http://web.archive.org/web/20100228145846/http://x264dev.multimedia.cx/?p=317},
year = {2010}
}
@misc{Weisstein2015a,
author = {Weisstein, Eric W.},
booktitle = {Wolfram Mathworld},
mendeley-groups = {Dissertation/BirdsongFeatures},
title = {{Wavelet}},
url = {http://mathworld.wolfram.com/Wavelet.html},
year = {2015}
}
@book{Chui1992,
address = {San Diego},
author = {Chui, Charles K.},
mendeley-groups = {Dissertation/BirdsongFeatures},
publisher = {Academic Press},
title = {{An Introduction to Wavelets}},
year = {1992}
}
@article{Almeida2003,
abstract = {Linear Independent Components Analysis (ICA) has become an important signal processing and data analysis technique, the typical application being blind source separation in a wide range of signals, such as biomedical, acoustical and astrophysical ones. Nonlinear ICA is less developed, but has the potential to become at least as powerful.This paper presents MISEP, an ICA technique for linear and nonlinear mixtures, which is based on the minimization of the mutual information of the estimated components. MISEP is a generalization of the popular INFOMAX technique, which is extended in two ways: (1) to deal with nonlinear mixtures, and (2) to be able to adapt to the actual statistical distributions of the sources, by dynamically estimating the nonlinearities to be used at the outputs. The resulting MISEP method optimizes a network with a specialized architecture, with a single objective function: the output entropy.The paper also briefly discusses the issue of nonlinear source separation. Examples of linear and nonlinear source separation performed by MISEP are presented.},
author = {Almeida, Lb},
doi = {10.1162/jmlr.2003.4.7-8.1297},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/almeida03a.pdf:pdf},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
keywords = {blind source separation,ica,mutual information,nonlinear ica},
mendeley-groups = {Dissertation},
pages = {1297--1318},
title = {{MISEP—linear and nonlinear ICA based on mutual information}},
url = {http://dl.acm.org/citation.cfm?id=964307},
volume = {4},
year = {2003}
}
@article{Omar,
author = {Omar, Mohamed Kamal and Hasegawa-johnson, Mark},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/omar03ccct.pdf:pdf},
mendeley-groups = {Dissertation},
title = {{Non-Linear Independent Component Analysis for Speech Recognition Analysis}}
}
@article{Zhao2012,
author = {Zhao, Huan and Zhao, Kai and Liu, He and Yu, Fei},
doi = {10.4304/jmm.7.1.74-81},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/6761-14719-1-PB.pdf:pdf},
issn = {17962048},
journal = {Journal of Multimedia},
keywords = {Independent component analysis,Speech feature extraction,Speech recognition},
mendeley-groups = {Dissertation},
number = {1},
pages = {74--81},
title = {{Improved MFCC feature extraction combining symmetric ICA algorithm for robust speech recognition}},
volume = {7},
year = {2012}
}
@article{Systems1989,
author = {Systems, Gird},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/GIRD\_Systems\_Intro\_to\_MUSIC\_ESPRIT.pdf:pdf},
mendeley-groups = {Dissertation},
number = {3},
title = {{An Introduction to MUSIC and ESPRIT}},
volume = {34},
year = {1989}
}
@misc{Evans,
author = {Evans, Brian L.},
mendeley-groups = {Dissertation},
title = {{MUSIC Algorithm}},
url = {http://ptolemy.eecs.berkeley.edu/papers/96/dtmf\_ict/www/node5.html}
}
@article{Kootsookos1999,
abstract = {This report presents a concise review of some frequency estimation and frequency tracking problems. In particular, the report focusses on aspects of these problems which have been addressed by members of the Frequency Tracking and Estimation project of the Centre for Robust and Adaptive Systems. The report is divided into four parts: problem specification and discussion, associ- ated problems, frequency estimation algorithms and frequency tracking algorithms. Part I begins with a definition of the various frequency estimation and tracking problems. Practical examples of where each problem may arise are given. A com- parison is made between the frequency estimation and tracking problems. In Part II, block frequency estimation algorithms, fast block frequency estimation algorithms and notch filtering techniques for frequency estimation are dealt with. Frequency tracking algorithms are examined in Part III. Part IV of this report examines various problems associated with frequency esti- mation. Associated problems include Cram er-Rao lower bounds, theoretical algo- rithm performance, frequency resolution, use of the analytic signal and model order selection.},
author = {Kootsookos, P J},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/comparison-t.pdf:pdf},
journal = {Order A Journal On The Theory Of Ordered Sets And Its Applications},
mendeley-groups = {Dissertation},
title = {{A Review of the Frequency Estimation and Tracking Problems Frequency Estimation and Tracking Problems}},
url = {http://espace.library.uq.edu.au/view/UQ:10626},
year = {1999}
}
@misc{Mathworks2015,
author = {Mathworks, The},
mendeley-groups = {Dissertation},
title = {{Pseudospectrum using MUSIC algorithm}},
url = {http://uk.mathworks.com/help/signal/ref/pmusic.html},
year = {2015}
}
@article{Delft2011,
author = {Delft, TU},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/8b\_spectra.pdf:pdf},
mendeley-groups = {Dissertation},
number = {et 4235},
title = {{Parametric Spectrum Estimation}},
year = {2011}
}




@article{Kasprzak,
author = {Kasprzak, Włodzimierz and Okazaki, Adam F},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/IWSSIP04.pdf:pdf},
keywords = {independent components,speaker identification,speech features,unsupervised learning},
mendeley-groups = {Dissertation},
title = {{Applying Independent Component Analysis for Speech Feature Detection}},
volume = {1}
}
@article{Kasprzak2006,
author = {Kasprzak, Wlodzimierz and Okazaki, Adam F and Kowalski, Adam B},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/ICA06.pdf:pdf},
mendeley-groups = {Dissertation},
pages = {609--616},
title = {{ICA-Based Speech Features in the Frequency Domain}},
year = {2006}
}
@article{Hsieh2009,
abstract = {Independent component analysis (ICA) is not only popular for blind source separation but also for unsupervised learning when the observations can be decomposed into some independent components. These components represent the specific speaker, gender, accent, noise or environment, and act as the basis functions to span the vector space of the human voices in different conditions. Different from eigenvoices built by principal component analysis, the proposed independent voices are estimated by ICA algorithm, and are applied for efficient coding of an adapted acoustic model. Since the information redundancy is significantly reduced in independent voices, we effectively calculate a coordinate vector in independent voice space, and estimate the hidden Markov models (HMMs) for speech recognition. In the experiments, we build independent voices from HMMs under different noise conditions, and find that these voices attain larger redundancy reduction than eigenvoices. The noise adaptive HMMs generated by independent voices achieve better recognition performance than those by eigenvoices.},
author = {Hsieh, Hsin-Lung and Chien, Jen-Tzung and Shinoda, K and Furui, S},
doi = {10.1109/ICASSP.2009.4960597},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/04960597.pdf:pdf},
isbn = {1520-6149 VO -},
journal = {Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on},
keywords = {blind source separation,eigenvoices,hidden Markov models,independent component analysis,noisy speech recognition,speech recognition},
mendeley-groups = {Dissertation},
pages = {4369--4372},
title = {{Independent component analysis for noisy speech recognition}},
year = {2009}
}
@article{Chien2006,
author = {Chien, Jen-tzung and Member, Senior and Chen, Bo-cheng},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/01643652.pdf:pdf},
journal = {Language},
mendeley-groups = {Dissertation},
number = {4},
pages = {1245--1254},
title = {{A New Independent Component Analysis for Speech Recognition and Separation}},
volume = {14},
year = {2006}
}
@article{Lee2000,
abstract = {In this paper, we proposed new speech features using independent component analysis to human speeches. When independent component analysis is applied to speech signals for efficient encoding the adapted basis functions resemble Gabor-like features. Trained basis functions have some redundancies, so we select some of the basis functions by the reordering method. The basis functions are almost ordered from the low frequency basis vector to the high frequency basis vector. And this is compatible with the fact that human speech signals have much more information in the low frequency range. Those features can be used in automatic speech recognition systems and the proposed method gives much better recognition rates than conventional mel-frequency cepstral features},
author = {Lee, Jong-Hwan and Jung, Ho-Young and Lee, Te-Won and Lee, Soo-Young},
doi = {10.1109/ICASSP.2000.862023},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/10.1.1.43.193.pdf:pdf},
isbn = {0-7803-6293-4},
journal = {2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (ICASSP)},
mendeley-groups = {Dissertation},
pages = {1631--1634},
title = {{Speech feature extraction using independent component analysis}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=862023\&abstractAccess=no\&userType=inst},
volume = {3},
year = {2000}
}
@article{Jang2001,
author = {Jang, Gil-jin and Lee, Te-won and Oh, Yung-hwan and Jolla, La},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/ica2001.pdf:pdf},
mendeley-groups = {Dissertation},
number = {1},
pages = {595--600},
title = {{BLIND SEPARATION OF SINGLE CHANNEL MIXTURE USING ICA BASIS FUNCTIONS Institute for Neural Computation , University of California , San Diego Spoken Language Laboratory , Department of Computer Science Korea Advanced Institute of Science and Technology Tae}},
year = {2001}
}
@misc{Linguistics2001,
author = {and Linguistics, UCL Department of Phonetics},
mendeley-groups = {Dissertation/Formants},
title = {{Lecture 10: Speech Signal Analysis}},
url = {http://www.phon.ucl.ac.uk/courses/spsci/matlab/lect10.html},
year = {2001}
}
@misc{Mathworks2015,
author = {Mathworks, The},
mendeley-groups = {Dissertation/Formants},
title = {{Formant Estimation with LPC Coefficients}},
year = {2015}
}
@article{Prica2010,
author = {Prica, Biljana and Ilic, Sinisa},
doi = {10.2298/FUEE1003379P},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/formants/0353-36701003379P.pdf:pdf},
issn = {0353-3670},
journal = {Facta universitatis - series: Electronics and Energetics},
keywords = {continuous speech,formants,recognition of vowels,serbian speech},
mendeley-groups = {Dissertation/Formants},
number = {3},
pages = {379--393},
title = {{Recognition of vowels in continuous speech by using formants}},
volume = {23},
year = {2010}
}
@article{Hosom2006,
author = {Hosom, John-Paul},
mendeley-groups = {Dissertation/Formants},
title = {{Estimating Speech Parameters}},
year = {2006}
}
@misc{Snell1993,
author = {Snell, Roy C.},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/formants/SnelM93-fmnt.pdf:pdf},
mendeley-groups = {Dissertation/Formants},
publisher = {IEEE},
title = {{Formant Location Drom LPC Analysis Data}},
year = {1993}
}
@article{Teplitsky2000,
author = {Teplitsky, Vladislav and Modeling, Speech},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/formants/vlad\_present.pdf:pdf},
journal = {Spring},
mendeley-groups = {Dissertation/Formants},
pages = {1--15},
title = {{Implementation of Linear Predictive Coding ( LPC ) of Speech}},
year = {2000}
}
@article{Corrigan2010,
author = {Corrigan, David},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/formants/DSP2\_2012\_students.pdf:pdf},
mendeley-groups = {Dissertation/Formants},
pages = {1--18},
title = {{The Z Transform , System Transfer Function , Poles and Stability}},
year = {2010}
}
@book{Ferragne2010,
abstract = {This study is a formant-based investigation of the vowels of male$\backslash$nspeakers in 13 accents of the British Isles. It provides F1/F2 graphs$\backslash$n(obtained with a semi-automatic method) which could be used as starting$\backslash$npoints for more thorough analyses. The article focuses on both phonetic$\backslash$nrealization and systemic phenomena, and it also provides detailed$\backslash$ninformation on automatic formant measurements. The aim is to obtain$\backslash$nan up-to-date picture of withinand between-accent vowel variation$\backslash$nin the British Isles. F1/F2 graphs plot z-scored Barktransformed$\backslash$nformant frequencies, and values in Hertz are also provided. Along$\backslash$nwith the findings, a number of methodological issues are addressed.},
author = {Ferragne, Emmanuel and Pellegrino, Fran\c{c}ois},
booktitle = {Journal of the International Phonetic Association},
doi = {10.1017/S0025100309990247},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/formants/S0025100309990247a.pdf:pdf},
isbn = {0025100309990},
issn = {0025-1003},
mendeley-groups = {Dissertation/Formants},
number = {01},
pages = {1},
title = {{Formant frequencies of vowels in 13 accents of the British Isles}},
volume = {40},
year = {2010}
}
@article{Cont2011,
abstract = {This paper proposes methods for information processing of audio streams using methods of information geometry. We lay the theoretical groundwork for a framework allowing the treatment of signal information as information entities, suitable for similarity and symbolic computing on audio signals. The theoretical basis of this paper is based on the information geometry of statistical structures representing audio spectrum features, and specifically through the bijection between the generic families of Bregman divergences and that of exponential distributions. The proposed framework, called Music Information Geometry, allows online segmentation of audio streams to metric balls where each ball represents a quasi-stationary continuous chunk of audio, and discusses methods to qualify and quantify information between entities for similarity computing. We define an information geometry that approximates a similarity metric space, redefine general notions in music information retrieval such as similarity between entities, and address methods for dealing with nonstationarity of audio signals. We demonstrate the framework on two sample applications for online audio structure discovery and audio matching.},
author = {Cont, Arshia and Dubnov, Shlomo and Assayag, G\'{e}rard},
doi = {10.1109/TASL.2010.2066266},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/index.pdf:pdf},
isbn = {1558-7916},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Information geometry,music information retrieval (MIR)},
mendeley-groups = {Dissertation/BirdsongFeatures},
number = {4},
pages = {837--846},
title = {{On the information geometry of audio streams with applications to similarity computing}},
volume = {19},
year = {2011}
}
@article{Gunawardana2001,
author = {Gunawardana, Asela Jeevaka Ranaweera},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/gunawardana01\_\_infor\_geomet\_em\_varian\_speec\_image\_proces.pdf:pdf},
issn = {04194217},
journal = {Dissertation Abstracts International, B: Sciences and Engineering},
mendeley-groups = {Dissertation/BirdsongFeatures},
number = {2},
title = {{The Information Geometry of EM Variants for Speech and Image Processing}},
volume = {62},
year = {2001}
}
@article{Wang2009,
author = {Wang, Shijun and Jin, Rong},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/wang09c.pdf:pdf},
journal = {Jmlr},
mendeley-groups = {Dissertation/BirdsongFeatures},
pages = {1--8},
title = {{An information geometry approach for distance metric learning}},
url = {papers2://publication/uuid/78E8E29A-A515-448B-9340-732FE58D6539},
volume = {5},
year = {2009}
}
@article{Sun,
author = {Sun, Ke and Marchand-maillet, St\'{e}phane},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/24\_paper.pdf:pdf},
keywords = {density estimation,information geometry,statistical learning},
mendeley-groups = {Dissertation/BirdsongFeatures},
title = {{Information Geometric Density Estimation}}
}
@article{Amari2001,
abstract = {An exponential family or mixture family of probability
distributions has a natural hierarchical structure. This paper gives an
\&amp;ldquo;orthogonal\&amp;rdquo; decomposition of such a system based on
information geometry. A typical example is the decomposition of
stochastic dependency among a number of random variables. In general,
they have a complex structure of dependencies. Pairwise dependency is
easily represented by correlation, but it is more difficult to measure
effects of pure triplewise or higher order interactions (dependencies)
among these variables. Stochastic dependency is decomposed
quantitatively into an \&amp;ldquo;orthogonal\&amp;rdquo; sum of pairwise,
triplewise, and further higher order dependencies. This gives a new
invariant decomposition of joint entropy. This problem is important for
extracting intrinsic interactions in firing patterns of an ensemble of
neurons and for estimating its functional connections. The orthogonal
decomposition is given in a wide class of hierarchical structures
including both exponential and mixture families. As an example, we
decompose the dependency in a higher order Markov chain into a sum of
those in various lower order Markov chains},
author = {Amari, S. I.},
doi = {10.1109/18.930911},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/amari-ig-hierarchy-01.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Decomposition of entropy,Extended Pythagoras theorem,Higher order Markov chain,Higher order interactions,Information geometry,Kullback divergence,e- and m-projections},
mendeley-groups = {Dissertation/BirdsongFeatures},
number = {5},
pages = {1701--1711},
title = {{Information geometry on hierarchy of probability distributions}},
volume = {47},
year = {2001}
}
@article{Goodall2008,
author = {Gutierrez-Osuna, Ricardo},
doi = {10.1111/j.1467-9639.2004.00168.x},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/kde/pr\_l7.pdf:pdf},
isbn = {1467-9639},
issn = {0141-982X},
journal = {Teaching Statistics},
mendeley-groups = {Dissertation},
number = {1998},
pages = {2009},
title = {{Kernel Density Estimation}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9639.2007.00314.x/full},
volume = {86},
year = {2008}
}
@article{Bellet2013,
abstract = {The need for appropriate ways to measure the distance or similarity between data is ubiquitous in machine learning, pattern recognition and data mining, but handcrafting such good metrics for specific problems is generally difficult. This has led to the emergence of metric learning, which aims at automatically learning a metric from data and has attracted a lot of interest in machine learning and related fields for the past ten years. This survey paper proposes a systematic review of the metric learning literature, highlighting the pros and cons of each approach. We pay particular attention to Mahalanobis distance metric learning, a well-studied and successful framework, but additionally present a wide range of methods that have recently emerged as powerful alternatives, including nonlinear metric learning, similarity learning and local metric learning. Recent trends and extensions, such as semi-supervised metric learning, metric learning for histogram data and the derivation of generalization guarantees, are also covered. Finally, this survey addresses metric learning for structured data, in particular edit distance learning, and attempts to give an overview of the remaining challenges in metric learning for the years to come.},
archivePrefix = {arXiv},
arxivId = {1306.6709},
author = {Bellet, Aur\'{e}lien and Habrard, Amaury and Sebban, Marc},
doi = {10.1073/pnas.0809777106},
eprint = {1306.6709},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/1306.6709v4.pdf:pdf},
issn = {00401951},
journal = {arXiv preprint arXiv:1306.6709},
keywords = {(),edit distance,mahalanobis distance,metric learning,similarity learning},
pages = {57},
pmid = {19342485},
title = {{A Survey on Metric Learning for Feature Vectors and Structured Data}},
url = {http://arxiv.org/abs/1306.6709},
year = {2013}
}
@article{Hershey2007,
author = {Hershey, John R and Olsen, Peder a},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/10.1.1.148.2502.pdf:pdf},
journal = {Acoustics, Speech and Signal Processing},
number = {6},
pages = {IV--317},
title = {{Approximating the Kullback-Leibler divergence between Gaussian mixture models}},
volume = {4},
year = {2007}
}
@article{Divergence2008,
author = {Osborne, Miles},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/entropy.pdf:pdf},
title = {{Kullback-Leibler Divergence}},
year = {2008}
}
@misc{KSMathworks2015,
author = {Mathworks, The},
mendeley-groups = {Dissertation},
title = {{Two-sample Kolmogorov-Smirnov test}},
url = {http://uk.mathworks.com/help/stats/kstest2.html},
year = {2015}
}
@article{Harsha2011,
author = {Harsha, Prahladh},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/l12.pdf:pdf},
mendeley-groups = {Dissertation},
pages = {1--8},
title = {{Hellinger Distance}},
volume = {2011},
year = {2011}
}
@article{Juang1985,
author = {Juang, B.-H. and Rabiner, L. R.},
doi = {10.1002/j.1538-7305.1985.tb00439.x},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/06770944.pdf:pdf},
issn = {87562324},
journal = {AT\&T Technical Journal},
mendeley-groups = {Dissertation},
number = {2},
pages = {391--408},
title = {{A Probabilistic Distance Measure for Hidden Markov Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6770944},
volume = {64},
year = {1985}
}
@article{Levinson1983,
author = {Levinson, Se},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/06768244.pdf:pdf},
journal = {Bell System Technical \ldots},
mendeley-groups = {Dissertation},
number = {4},
pages = {1035--1074},
title = {{An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6768244},
volume = {62},
year = {1983}
}
@article{Lyngs1999,
abstract = {Hidden Markov models were introduced in the beginning of the 1970's as a tool in speech recognition. During the last decade they have been found useful in addressing problems in computational biology such as characterising sequence families, gene finding, structure prediction and phylogenetic analysis. In this paper we propose several measures between hidden Markov models. We give an efficient algorithm that computes the measures for left-right models, e.g. profile hidden Markov models, and briefly discuss how to extend the algorithm to other types of models. We present an experiment using the measures to compare hidden Markov models for three classes of signal peptides.},
author = {Lyngs\o, R B and Pedersen, C N and Nielsen, H},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/10.1.1.462.2134.pdf:pdf},
isbn = {1-57735-083-9},
issn = {1553-0833},
journal = {Proc. Int. Conf. Intell. Syst. Mol. Biol},
keywords = {Algorithms,Markov Chains,Models,Peptides,Peptides: chemistry,Probability,Statistical},
mendeley-groups = {Dissertation},
pages = {178--86},
pmid = {10786300},
title = {{Metrics and similarity measures for hidden Markov models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10786300},
year = {1999}
}
@article{Bahlmann2001,
abstract = {We propose a novel similarity measure for hidden Markov models$\backslash$n(HMMs). This measure calculates the Bayes probability of error for HMM$\backslash$nstate correspondences and propagates it along the Viterbi path in a$\backslash$nsimilar way to the HMM Viterbi scoring. It can be applied as a tool to$\backslash$ninterpret misclassifications, as a stop criterion in iterative HMM$\backslash$ntraining or as a distance measure for HMM clustering. The similarity$\backslash$nmeasure is evaluated in the context of online handwriting recognition on$\backslash$nlower case character models which have been trained from the UNIPEN$\backslash$ndatabase. We compare the similarities with experimental classifications.$\backslash$nThe results show that similar and misclassified class pairs are highly$\backslash$ncorrelated. The measure is not limited to handwriting recognition, but$\backslash$ncan be used in other applications that use HMM based methods},
author = {Bahlmann, C. and Burkhardt, H.},
doi = {10.1109/ICDAR.2001.953822},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/ba\_bu\_icdar01.pdf:pdf},
isbn = {0-7695-1263-1},
journal = {Proceedings of Sixth International Conference on Document Analysis and Recognition},
mendeley-groups = {Dissertation},
pages = {406--411},
title = {{Measuring HMM similarity with the Bayes probability of error and$\backslash$nits application to online handwriting recognition}},
year = {2001}
}
@misc{HAGMathworks,
author = {Mathworks, The},
mendeley-groups = {Dissertation},
title = {{Hierarchical Clustering}},
url = {http://uk.mathworks.com/help/stats/hierarchical-clustering.html}
}
@article{.2006,
author = {., Satchidanandan Dehuri and ., Chinmay Mohapatra and ., Ashish Ghosh and ., Rajib Mall},
doi = {10.3923/itj.2006.551.559},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/1506.08977.pdf:pdf},
issn = {18125638},
journal = {Information Technology Journal},
keywords = {dendrogram,dissimilarity data,evaluation of,hierarchical clustering,hierarchy,splitting procedures,ultrametrics},
number = {3},
pages = {551--559},
title = {{A Comparative Study of Clustering Algorithms}},
volume = {5},
year = {2006}
}
@misc{Manning2009,
author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch\"{u}tze, Hinrich},
booktitle = {Stanford NLP},
mendeley-groups = {Dissertation},
title = {{Introduction to Information Retrieval}},
year = {2009}
}
@article{Psorakis2010a,
abstract = {Identifying overlapping communities in networks is a challenging task. In this work we present a novel approach to community detection that utilizes the Bayesian non-negative matrix factorization (NMF) model to extract overlapping modules from a network. The scheme has the advantage of computational effi- ciency, soft community membership and an intuitive foundation. We present the performance of the method against a variety of benchmark problems and compare and contrast it to several other algorithms for community detection.},
author = {Psorakis, Ioannis and Roberts, Stephen and Sheldon, Ben},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/psorakis\_roberts\_sheldon\_nips2010.pdf:pdf},
journal = {Nips},
pages = {1--8},
title = {{Soft Partitioning in Networks via Bayesian Non-negative Matrix Factorization}},
year = {2010}
}
@book{Oppenheim2010,
author = {Oppenheim, Alan V. and Schafer, Roland W.},
edition = {3},
publisher = {Pearson},
title = {{Discrete-Time Signal Processing}},
year = {2010}
}
@article{Roberts2014,
author = {Roberts, Stephen},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/ar/lect4.pdf:pdf},
mendeley-groups = {Dissertation},
title = {{Lecture 4 Stochastic Process Models \& Multivariate Systems}},
year = {2014}
}
@article{Forecasting,
author = {Forecasting, Harrison Bayesian},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/ar/214.8 (ARp).pdf:pdf},
mendeley-groups = {Dissertation},
pages = {1--12},
title = {{Autoregressive Models}}
}
@article{Johnston,
author = {Johnston, Ryan},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/ar/ar1.pdf:pdf},
journal = {Time},
mendeley-groups = {Dissertation},
number = {1},
pages = {1--12},
title = {{AR ( 1 ) TIME SERIES PROCESS Econometrics 7590}}
}
@article{Collomb2009,
author = {Collomb, Cedrick},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/ar/a tutorial on linear prediction and levinson-durbin.pdf:pdf},
journal = {Thinking},
mendeley-groups = {Dissertation},
pages = {1--7},
title = {{Linear Prediction and Levinson-Durbin Algorithm}},
year = {2009}
}
@article{Teplitsky2000,
author = {Teplitsky, Vladislav and Modeling, Speech},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/feature\_extraction/formants/vlad\_present.pdf:pdf},
journal = {Spring},
mendeley-groups = {Dissertation},
pages = {1--15},
title = {{Implementation of Linear Predictive Coding ( LPC ) of Speech}},
year = {2000}
}
@misc{Wissman2006,
author = {Wissman, Margaret},
mendeley-groups = {Dissertation},
title = {{Avian Anatomy}},
url = {http://www.exoticpetvet.net/avian/anatomy.html},
year = {2006}
}
@article{NationalInstruments2015,
author = {{National Instruments}},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/signals/NI-Tutorial-4844-en.pdf:pdf},
pages = {1--11},
title = {{Understanding FFTs and Windowing}},
year = {2015}
}
@misc{Weisstein2015b,
author = {Weisstein, Eric W.},
title = {{Nyquist Frequency}},
year = {2015}
}
@misc{Jang1996,
author = {Jang, Roger},
title = {{Audio Signal Processing and Recognition}},
url = {http://mirlab.org/jang/books/audiosignalprocessing/},
year = {1996}
}
@article{Shimodaira2013,
author = {Shimodaira, Hiroshi and Renals, Steve},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/signals/asr02-signal-4up.pdf:pdf},
title = {{Speech Signal Analysis Speech signal analysis for ASR Acoustic Features for ASR Acoustic Features for ASR MFCC-based front end for ASR}},
volume = {2},
year = {2013}
}
@misc{Raschka2014,
author = {Raschka, Sebastian},
title = {{About Feature Scaling and Normalization}},
year = {2014}
}
@misc{Weisstein2015c,
author = {Weisstein, Eric},
mendeley-groups = {Dissertation},
title = {{Wiener-Khinchin Theorem}},
url = {http://mathworld.wolfram.com/Wiener-KhinchinTheorem.html},
year = {2015}
}
@misc{Hansen2009,
author = {Hansen, Bruce E.},
mendeley-groups = {Dissertation/AbstractStructures},
title = {{Lecture Notes on Nonparametrics}},
url = {http://www.ssc.wisc.edu/~bhansen/718/NonParametrics1.pdf},
urldate = {2015-08-17},
year = {2009}
}
@misc{Duong2004,
author = {Duong, Tarn},
mendeley-groups = {Dissertation/AbstractStructures},
title = {{An introduction to kernel density estimation}},
url = {http://www.mvstat.net/tduong/research/seminars/seminar-2001-05/},
year = {2004}
}
@article{Rezek2005,
abstract = {Hidden Markov Models (HMM) have proven to be very useful in a
  variety of biomedical applications. The most established method for
  estimating HMM parameters is the maximum likelihood method which has
  shortcomings, such as repeated estimation and penalisation of the
  likelihood score, that are well known. This paper describes an
  Variational learning approach to try and improve on the
  maximum-likelihood estimators. Emphasis lies on the fact, that for
  HMMs with observation models that are from the exponential family of
  distributions, all HMM parameters and hidden state variables can be
  derived from a single loss function, namely the Kullback-Leibler
  Divergence. Practical issues, such as model initialisation and choice
  of model order, are described. The paper concludes by application of
  3 types of observation model HMMs to a variety of biomedical data,
  such as EEG and ECG, from different physiological experiments and
  conditions.},
author = {Rezek, Iead and Roberts, Stephen J.},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/varhmm.pdf:pdf},
keywords = {Brain Computer Interfaces,Computational, Information-Theoretic Learning with},
mendeley-groups = {Dissertation,Dissertation/Hmms},
title = {{Ensemble Hidden Markov Models with Extended Observation Densities for Biosignal Analysis}},
url = {http://eprints.pascal-network.org/archive/00001124/},
year = {2005}
}
@article{Siddiqi2007,
abstract = {Choosing the number of hidden states and their topology (model selection)$\backslash$nand estimating model parameters (learning) are important problems$\backslash$nfor Hidden Markov Models. This paper presents a new state-splitting$\backslash$nalgorithm that addresses both these problems. The algorithm models$\backslash$nmore information about the dynamic context of a state during a split,$\backslash$nenabling it to discover underlying states more effectively. Compared$\backslash$nto previous top-down methods, the algorithm also touches a smaller$\backslash$nfraction of the data per split, leading to faster model search and$\backslash$nselection. Because of its efficiency and ability to avoid local minima,$\backslash$nthe state-splitting approach is a good way to learn HMMs even if$\backslash$nthe desired number of states is known beforehand. We compare our$\backslash$napproach to previous work on synthetic data as well as several real-world$\backslash$ndata sets from the literature, revealing significant improvements$\backslash$nin efficiency and test-set likelihoods. We also compare to previous$\backslash$nalgorithms on a sign-language recognition task, with positive results.},
author = {Siddiqi, S and Gordon, G and Moore, a},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/siddiqi-gordon-moore.fast-hmm.pdf:pdf},
isbn = {15324435 (ISSN)},
issn = {15324435},
journal = {Proc. AISTATS},
mendeley-groups = {Dissertation/Hmms},
pages = {1--8},
title = {{Fast state discovery for HMM model selection and learning}},
url = {http://www.cs.cmu.edu/~ggordon/siddiqi-gordon-moore.fast-hmm.pdf},
year = {2007}
}
@article{Levy2012,
author = {Levy, Roger},
doi = {10.1016/S0921-9366(98)80007-8},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/pmsl\_4.pdf:pdf},
isbn = {9780444828019},
issn = {09219366},
journal = {Introduction to Meta Analysis},
mendeley-groups = {Dissertation/Hmms},
pages = {257--294},
title = {{Chapter 6 Parameter estimation}},
volume = {5},
year = {2012}
}
@article{MacKay1997,
author = {MacKay, D.J.C. and MacKay, D.J.C.},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/ensemblePaper.pdf:pdf},
journal = {Citeseer},
mendeley-groups = {Dissertation/Hmms},
pages = {0--6},
title = {{Ensemble learning for hidden Markov models}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Ensemble+Learning+for+Hidden+Markov+Models\#0},
year = {1997}
}
@article{Beal2001,
author = {Beal, Matthew},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/beal03\_3.pdf:pdf},
mendeley-groups = {Dissertation/Hmms},
number = {1997},
pages = {82--105},
title = {{Variational Bayesian Hidden Markov Models}},
year = {2001}
}
@article{Beal2003,
abstract = {We present an efficient procedure for estimating the marginal likelihood of probabilistic models with latent variables or incomplete data. This method constructs and optimises a lower bound on the marginal likelihood using variational calculus, resulting in an iterative algorithm which generalises the EM algorithm by maintaining posterior distributions over both latent variables and parameters. We define the family of conjugate-exponential models—which includes finite mixtures of exponential family models, factor analysis, hidden Markov models, linear state-space models, and other models of interest—for which this bound on the marginal likelihood can be computed very simply through a modification of the standard EM algorithm. In particular, we focus on applying these bounds to the problem of scoring discrete directed graphical model structures (Bayesian networks). Extensive simulations comparing the variational bounds to the usual approach based on the Bayesian Information Criterion (BIC) and to a sampling-based gold standard method known as Annealed Importance Sampling (AIS) show that variational bounds substantially outperform BIC in finding the correct model structure at relatively little computational cost, while approaching the performance of the much more costly AIS procedure. Using AIS allows us to provide the first serious case study of the tightness of variational bounds. We also analyse the perfomance of AIS through a variety of criteria, and outline directions in which this work can be extended.},
author = {Beal, Matthew J and Ghahramani, Zoubin},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/valencia02.pdf:pdf},
journal = {Bayesian statistics 7: proceedings of the seventh Valencia International Meeting, June 2-6, 2002},
keywords = {annealed importance sampling,bayes factors,graphical,latent variables,marginal likelihood,models,structure scoring,variational methods},
mendeley-groups = {Dissertation/Hmms},
pages = {453},
title = {{The variational Bayesian EM algorithm for incomplete data: with application to scoring graphical model structures}},
url = {papers2://publication/uuid/CA675505-6092-4BE3-8200-EDF80F490DB9},
year = {2003}
}
@article{Fox2010,
abstract = {This tutorial describes the mean-field variational Bayesian approximation to inference in graphical models, using modern machine learning terminology rather than statistical physics concepts. It begins by seeking to find an approximate mean- field distribution close to the target joint in the KL-divergence sense. It then derives local node updates and reviews the recent Variational Message Passing framework.},
author = {Fox, C W and Roberts, S J},
doi = {10.1007/s10462-011-9236-8},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/fox\_vbtut.pdf:pdf},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {mean-field,tutorial,variational bayes},
mendeley-groups = {Dissertation/Hmms},
pages = {1--11},
title = {{A tutorial on variational Bayesian inference}},
url = {papers2://publication/uuid/1B6D2DDA-67F6-4EEE-9720-2907FFB14789},
year = {2010}
}
@article{Genovese2004,
author = {Genovese, Christopher R},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/ipam-04.pdf:pdf},
mendeley-groups = {Dissertation/Hmms},
number = {July},
title = {{Tutorial on Bayesian Analysis ( in Neuroimaging )}},
year = {2004}
}
@article{Ghahramani2001,
author = {Ghahramani, Zoubin},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/ijprai.pdf:pdf},
mendeley-groups = {Dissertation/Hmms},
title = {{An Introduction to Hidden Markov Models and Bayesian Networks}},
volume = {1},
year = {2001}
}
@article{Ghahramani2003,
author = {Ghahramani, Zoubin},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/Zoubin-702.pdf:pdf},
mendeley-groups = {Dissertation/Hmms},
number = {April},
title = {{Variational Methods The Expectation Maximization ( EM ) algorithm}},
year = {2003}
}
@article{Nydick2012,
author = {Nydick, Steven W},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/hmm/Wishart\_Distribution.pdf:pdf},
pages = {1--19},
title = {{The Wishart and Inverse Wishart Distributions}},
year = {2012}
}
@article{Dasgupta,
author = {Dasgupta, Sanjoy},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/clustering/hw1.pdf:pdf},
mendeley-groups = {Dissertation/Clustering},
pages = {1--3},
title = {{Clustering with the L 1 -norm Clustering of nonnegative vectors Gaussian integrals Relation between EM algorithm and k-means clustering}}
}
@article{Rauber2008,
abstract = {We derive the Bhattacharyya distance between two Dirichlet densities. As an application we use image segmentation by a split-and-merge algorithm.},
author = {Rauber, T. W. and Conci, a. and Braun, T. and Berns, K.},
doi = {10.1109/IWSSIP.2008.4604388},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/clustering/04604388.pdf:pdf},
isbn = {9788022728560},
journal = {Proceedings of IWSSIP 2008 - 15th International Conference on Systems, Signals and Image Processing},
keywords = {Bhattacharyya distance,Dirichlet distribution,Probabilistic distance measures},
mendeley-groups = {Dissertation/Clustering},
number = {1},
pages = {145--148},
title = {{Bhattacharyya probabilistic distance of the dirichlet density and its application to split-and-merge image segmentation}},
year = {2008}
}
@book{Goshtasby2012,
author = {Goshtasby, a. Ardeshir},
doi = {10.1007/978-1-4471-2458-0},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/9781447124573-c2.pdf:pdf},
isbn = {978-1-4471-2457-3},
pages = {1--6},
title = {{Image Registration}},
url = {http://www.springerlink.com/index/10.1007/978-1-4471-2458-0},
year = {2012}
}
@article{Mathworks2015a,
author = {Mathworks, The},
mendeley-groups = {Dissertation},
title = {{Cophenetic correlation coefficient}},
url = {http://uk.mathworks.com/help/stats/cophenet.html?refresh=true},
year = {2015}
}
@article{Benesty,
author = {Benesty, Jacob},
mendeley-groups = {Dissertation},
title = {{Springer Handbook of Speech Processing}},
volume = {2008}
}
@article{Hornik2012,
abstract = {Clustering text documents is a fundamental task in modern data analysis, requiring approaches which perform well both in terms of solution quality and computational efficiency. Spherical k-means clustering is one approach to address both issues, employing cosine dissimilarities to perform prototype-based partitioning of term weight representations of the documents. This paper presents the theory underlying the standard spherical k-means problem and suitable extensions, and introduces the R extension package skmeans which provides a computational environment for spherical k-means clustering featuring several solvers: axed-point and genetic algorithm, and interfaces to two external solvers (CLUTO and Gmeans). Performance of these solvers is investigated by means of a large scale benchmark experiment.},
author = {Hornik, Kurt and Feinerer, Ingo and Kober, Martin and Buchta, Christian},
file = {:C$\backslash$:/Users/Bernardo/Dropbox/dissertation/articles/literature/v50i10.pdf:pdf},
journal = {Journal of Statistical Software},
keywords = {R,clustering,cosine dissimilarity,spherical,text mining},
number = {10},
pages = {1--22},
title = {{Spherical k-Means Clustering}},
volume = {50},
year = {2012}
}
@misc{TheEconomistOnline2011,
author = {{The Economist Online}},
title = {{Big Data: Drowning in numbers}},
url = {http://www.economist.com/blogs/dailychart/2011/11/big-data-0},
year = {2011}
}
@misc{AnimalSoundArchive2015,
author = {{Animal Sound Archive}},
title = {{Animal Sound Archive}},
url = {http://www.animalsoundarchive.org/},
year = {2015}
}
@misc{Xeno-cantoFoundation2015,
author = {{Xeno-canto Foundation}},
title = {{Xeno-Canto}},
url = {http://www.xeno-canto.org/},
year = {2015}
}
